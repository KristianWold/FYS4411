{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "hn = 3\n",
    "class Model(nn.Module):\n",
    "     \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.stepLength = 1.5\n",
    "        self.hidden = torch.zeros((1, hn))\n",
    "        \n",
    "        self.Whh = nn.Linear(hn, hn)\n",
    "        self.Whx = nn.Linear(1, hn, bias = False)\n",
    "        \n",
    "        self.layer1 = nn.Linear(1 + hn, 64)\n",
    "        self.layer2 = nn.Linear(64, 64)\n",
    "        self.layer3 = nn.Linear(64, 1)\n",
    "        \n",
    "        self.layer1.bias.data.fill_(0.01)\n",
    "        self.layer2.bias.data.fill_(0.01)\n",
    "        self.layer3.bias.data.fill_(0.01)\n",
    "      \n",
    "    \n",
    "    def forward_RNN(self, x):\n",
    "        self.hidden = torch.tanh(self.Whh(self.hidden) + self.Whx(x))\n",
    "        \n",
    "        \n",
    "    def forward_DNN(self, x):\n",
    "        \n",
    "        y = torch.cat((self.hidden.repeat(x.shape[0], 1), x), 1)\n",
    "        \n",
    "        y = torch.relu(self.layer1(y))\n",
    "        y = torch.relu(self.layer2(y))\n",
    "        y = self.layer3(y)\n",
    "\n",
    "     \n",
    "        return y#*torch.exp(-0.1*x**2)\n",
    "    \n",
    "    def sample(self, n):\n",
    "        total = 0\n",
    "        x = torch.Tensor([[0]])#torch.Tensor(4*np.random.random((1,1)) - 2)\n",
    "        psi_old = self.forward_DNN(x)\n",
    "        \n",
    "        for i in range(n):\n",
    "            x_new = x + self.stepLength*torch.Tensor(2*np.random.random((1,1)) - 1)\n",
    "            psi_new = self.forward_DNN(x_new)\n",
    "            \n",
    "            if (psi_new/psi_old)**2 > np.random.random():\n",
    "                x = x_new\n",
    "                psi_old = psi_new\n",
    "                total += 1\n",
    "            \n",
    "        return x, total\n",
    "    \n",
    "    def resetHidden(self):\n",
    "        self.hidden = torch.zeros((1, hn))\n",
    "        self.forward_RNN(torch.zeros((1, 1)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "model = Model()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using naive minimization of energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/400 [00:00<01:38,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4424,  0.4782, -0.1363],\n",
      "        [ 0.5294, -0.1255,  0.1175],\n",
      "        [-0.2801,  0.3381,  0.5080]], requires_grad=True)\n",
      "epoch: 0, Grad: 69601.3203125, Energy: 24.34436798095703, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 11/400 [00:02<01:33,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4486,  0.4721, -0.1424],\n",
      "        [ 0.5215, -0.1176,  0.1253],\n",
      "        [-0.2721,  0.3301,  0.5000]], requires_grad=True)\n",
      "epoch: 10, Grad: 1308.998291015625, Energy: 15.167981147766113, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 21/400 [00:04<01:24,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4544,  0.4662, -0.1482],\n",
      "        [ 0.5163, -0.1125,  0.1303],\n",
      "        [-0.2662,  0.3242,  0.4941]], requires_grad=True)\n",
      "epoch: 20, Grad: 6982.6142578125, Energy: 9.134971618652344, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 31/400 [00:07<01:24,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4613,  0.4593, -0.1551],\n",
      "        [ 0.5105, -0.1067,  0.1359],\n",
      "        [-0.2626,  0.3206,  0.4905]], requires_grad=True)\n",
      "epoch: 30, Grad: 1048.475830078125, Energy: 7.423709392547607, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 41/400 [00:09<01:22,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4684,  0.4523, -0.1620],\n",
      "        [ 0.5041, -0.1003,  0.1419],\n",
      "        [-0.2604,  0.3184,  0.4884]], requires_grad=True)\n",
      "epoch: 40, Grad: 11571.986328125, Energy: 10.881192207336426, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 51/400 [00:11<01:21,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4754,  0.4453, -0.1688],\n",
      "        [ 0.4967, -0.0929,  0.1489],\n",
      "        [-0.2594,  0.3174,  0.4875]], requires_grad=True)\n",
      "epoch: 50, Grad: 905.174560546875, Energy: 6.077193737030029, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 61/400 [00:14<01:20,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4827,  0.4380, -0.1760],\n",
      "        [ 0.4880, -0.0844,  0.1574],\n",
      "        [-0.2638,  0.3218,  0.4918]], requires_grad=True)\n",
      "epoch: 60, Grad: 3541.05859375, Energy: 6.657985687255859, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 71/400 [00:16<01:16,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4872,  0.4336, -0.1806],\n",
      "        [ 0.4844, -0.0807,  0.1609],\n",
      "        [-0.2653,  0.3232,  0.4932]], requires_grad=True)\n",
      "epoch: 70, Grad: 19.022045135498047, Energy: 3.25184965133667, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 81/400 [00:18<01:16,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4897,  0.4311, -0.1831],\n",
      "        [ 0.4813, -0.0777,  0.1640],\n",
      "        [-0.2677,  0.3256,  0.4957]], requires_grad=True)\n",
      "epoch: 80, Grad: 1772.050048828125, Energy: 4.741103649139404, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 91/400 [00:21<01:11,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4913,  0.4295, -0.1848],\n",
      "        [ 0.4773, -0.0738,  0.1682],\n",
      "        [-0.2727,  0.3305,  0.5008]], requires_grad=True)\n",
      "epoch: 90, Grad: 137966.3125, Energy: 48.31096649169922, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 101/400 [00:23<01:07,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4917,  0.4291, -0.1852],\n",
      "        [ 0.4712, -0.0678,  0.1748],\n",
      "        [-0.2796,  0.3373,  0.5080]], requires_grad=True)\n",
      "epoch: 100, Grad: 2948.15576171875, Energy: 9.40233039855957, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 111/400 [00:25<01:07,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4927,  0.4281, -0.1863],\n",
      "        [ 0.4679, -0.0646,  0.1785],\n",
      "        [-0.2831,  0.3408,  0.5119]], requires_grad=True)\n",
      "epoch: 110, Grad: 101.04386901855469, Energy: 7.14664888381958, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 121/400 [00:28<01:03,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4939,  0.4269, -0.1879],\n",
      "        [ 0.4641, -0.0609,  0.1828],\n",
      "        [-0.2859,  0.3436,  0.5149]], requires_grad=True)\n",
      "epoch: 120, Grad: 111.81784057617188, Energy: 3.68540096282959, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 131/400 [00:30<01:02,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4947,  0.4262, -0.1887],\n",
      "        [ 0.4597, -0.0564,  0.1880],\n",
      "        [-0.2883,  0.3459,  0.5176]], requires_grad=True)\n",
      "epoch: 130, Grad: 284.854248046875, Energy: 3.688021183013916, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 141/400 [00:32<01:04,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4954,  0.4255, -0.1896],\n",
      "        [ 0.4566, -0.0534,  0.1916],\n",
      "        [-0.2894,  0.3471,  0.5189]], requires_grad=True)\n",
      "epoch: 140, Grad: 10.004868507385254, Energy: 2.8813652992248535, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 151/400 [00:35<01:01,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4962,  0.4246, -0.1907],\n",
      "        [ 0.4546, -0.0513,  0.1941],\n",
      "        [-0.2903,  0.3480,  0.5200]], requires_grad=True)\n",
      "epoch: 150, Grad: 467.57745361328125, Energy: 7.411036014556885, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 161/400 [00:37<00:55,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4970,  0.4238, -0.1917],\n",
      "        [ 0.4523, -0.0490,  0.1968],\n",
      "        [-0.2913,  0.3490,  0.5211]], requires_grad=True)\n",
      "epoch: 160, Grad: 711.8968505859375, Energy: 5.407445907592773, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 171/400 [00:40<00:52,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4977,  0.4231, -0.1926],\n",
      "        [ 0.4509, -0.0477,  0.1985],\n",
      "        [-0.2909,  0.3486,  0.5207]], requires_grad=True)\n",
      "epoch: 170, Grad: 16.018352508544922, Energy: 5.0361528396606445, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 181/400 [00:42<00:48,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4983,  0.4226, -0.1933],\n",
      "        [ 0.4505, -0.0472,  0.1990],\n",
      "        [-0.2901,  0.3478,  0.5197]], requires_grad=True)\n",
      "epoch: 180, Grad: 180.67095947265625, Energy: 4.667830467224121, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 191/400 [00:44<00:48,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.5010,  0.4198, -0.1965],\n",
      "        [ 0.4488, -0.0455,  0.2008],\n",
      "        [-0.2874,  0.3451,  0.5166]], requires_grad=True)\n",
      "epoch: 190, Grad: 12284187.0, Energy: 542.5588989257812, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 201/400 [00:46<00:46,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.5092,  0.4116, -0.2049],\n",
      "        [ 0.4405, -0.0373,  0.2092],\n",
      "        [-0.2810,  0.3386,  0.5099]], requires_grad=True)\n",
      "epoch: 200, Grad: 387.3519287109375, Energy: 22.363367080688477, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 211/400 [00:49<00:43,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.5127,  0.4081, -0.2084],\n",
      "        [ 0.4361, -0.0329,  0.2138],\n",
      "        [-0.2799,  0.3375,  0.5088]], requires_grad=True)\n",
      "epoch: 210, Grad: 197.6273956298828, Energy: 18.261913299560547, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 221/400 [00:51<00:42,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.5143,  0.4065, -0.2102],\n",
      "        [ 0.4332, -0.0300,  0.2169],\n",
      "        [-0.2804,  0.3381,  0.5095]], requires_grad=True)\n",
      "epoch: 220, Grad: 319.7735595703125, Energy: 26.681934356689453, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 231/400 [00:54<00:39,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.5155,  0.4054, -0.2114],\n",
      "        [ 0.4308, -0.0276,  0.2194],\n",
      "        [-0.2818,  0.3394,  0.5111]], requires_grad=True)\n",
      "epoch: 230, Grad: 1066.8065185546875, Energy: 19.862215042114258, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 241/400 [00:56<00:38,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.5165,  0.4043, -0.2125],\n",
      "        [ 0.4282, -0.0250,  0.2223],\n",
      "        [-0.2842,  0.3418,  0.5138]], requires_grad=True)\n",
      "epoch: 240, Grad: 134.1431884765625, Energy: 14.957232475280762, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 251/400 [00:58<00:35,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.5176,  0.4033, -0.2137],\n",
      "        [ 0.4255, -0.0223,  0.2253],\n",
      "        [-0.2868,  0.3444,  0.5168]], requires_grad=True)\n",
      "epoch: 250, Grad: 109.3150863647461, Energy: 12.379985809326172, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 261/400 [01:01<00:32,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.5186,  0.4022, -0.2149],\n",
      "        [ 0.4229, -0.0196,  0.2283],\n",
      "        [-0.2894,  0.3471,  0.5199]], requires_grad=True)\n",
      "epoch: 260, Grad: 310.37689208984375, Energy: 15.712151527404785, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 271/400 [01:03<00:29,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.5195,  0.4013, -0.2160],\n",
      "        [ 0.4204, -0.0171,  0.2312],\n",
      "        [-0.2919,  0.3497,  0.5230]], requires_grad=True)\n",
      "epoch: 270, Grad: 14.355228424072266, Energy: 11.220366477966309, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 281/400 [01:05<00:29,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.5203,  0.4005, -0.2169],\n",
      "        [ 0.4187, -0.0153,  0.2333],\n",
      "        [-0.2939,  0.3517,  0.5254]], requires_grad=True)\n",
      "epoch: 280, Grad: 140.04681396484375, Energy: 6.352846622467041, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 291/400 [01:08<00:25,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.5206,  0.4002, -0.2172],\n",
      "        [ 0.4181, -0.0147,  0.2340],\n",
      "        [-0.2947,  0.3525,  0.5264]], requires_grad=True)\n",
      "epoch: 290, Grad: 1438.7899169921875, Energy: 6.614797592163086, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 301/400 [01:10<00:22,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.5206,  0.4002, -0.2172],\n",
      "        [ 0.4177, -0.0144,  0.2344],\n",
      "        [-0.2952,  0.3530,  0.5270]], requires_grad=True)\n",
      "epoch: 300, Grad: 26.85267448425293, Energy: 3.679136276245117, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 311/400 [01:12<00:21,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.5204,  0.4004, -0.2170],\n",
      "        [ 0.4180, -0.0146,  0.2341],\n",
      "        [-0.2948,  0.3527,  0.5266]], requires_grad=True)\n",
      "epoch: 310, Grad: 61.481056213378906, Energy: 4.41290807723999, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 321/400 [01:15<00:17,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.5204,  0.4003, -0.2171],\n",
      "        [ 0.4180, -0.0146,  0.2341],\n",
      "        [-0.2949,  0.3528,  0.5267]], requires_grad=True)\n",
      "epoch: 320, Grad: 102.04354858398438, Energy: 4.156288146972656, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 331/400 [01:17<00:15,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.5205,  0.4002, -0.2172],\n",
      "        [ 0.4180, -0.0147,  0.2340],\n",
      "        [-0.2949,  0.3527,  0.5266]], requires_grad=True)\n",
      "epoch: 330, Grad: 28.449634552001953, Energy: 4.384668827056885, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 341/400 [01:19<00:13,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.5205,  0.4003, -0.2172],\n",
      "        [ 0.4186, -0.0152,  0.2334],\n",
      "        [-0.2941,  0.3519,  0.5257]], requires_grad=True)\n",
      "epoch: 340, Grad: 21.061710357666016, Energy: 3.7226381301879883, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 351/400 [01:21<00:10,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.5197,  0.4011, -0.2162],\n",
      "        [ 0.4187, -0.0154,  0.2332],\n",
      "        [-0.2941,  0.3519,  0.5257]], requires_grad=True)\n",
      "epoch: 350, Grad: 14.018996238708496, Energy: 3.8858909606933594, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 361/400 [01:24<00:08,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.5211,  0.3997, -0.2178],\n",
      "        [ 0.4157, -0.0122,  0.2366],\n",
      "        [-0.2959,  0.3538,  0.5278]], requires_grad=True)\n",
      "epoch: 360, Grad: 111.10143280029297, Energy: 5.111301898956299, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 371/400 [01:26<00:06,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.5244,  0.3963, -0.2217],\n",
      "        [ 0.4099, -0.0064,  0.2429],\n",
      "        [-0.2994,  0.3574,  0.5320]], requires_grad=True)\n",
      "epoch: 370, Grad: 141.81166076660156, Energy: 10.42216968536377, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 381/400 [01:28<00:04,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.5260,  0.3946, -0.2237],\n",
      "        [ 0.4076, -0.0041,  0.2455],\n",
      "        [-0.3015,  0.3596,  0.5346]], requires_grad=True)\n",
      "epoch: 380, Grad: 1534.876220703125, Energy: 13.805782318115234, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 391/400 [01:30<00:02,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.5270,  0.3936, -0.2248],\n",
      "        [ 0.4067, -0.0031,  0.2466],\n",
      "        [-0.3026,  0.3607,  0.5360]], requires_grad=True)\n",
      "epoch: 390, Grad: 105.44309997558594, Energy: 6.506765365600586, N:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [01:33<00:00,  4.30it/s]\n"
     ]
    }
   ],
   "source": [
    "epochs = 400\n",
    "N = 32\n",
    "n = 20\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    PE_acc = 0\n",
    "    P_acc = 0\n",
    "    E_acc = 0\n",
    "    grad = 0\n",
    "    \n",
    "    for i in range(N):\n",
    "        psi_total = 1\n",
    "        \n",
    "        model.resetHidden() \n",
    "        x1 = model.sample(n)[0].detach().requires_grad_()\n",
    "        psi1 = model.forward_DNN(x1)\n",
    "        \n",
    "        model.forward_RNN(x1)\n",
    "        x2 = model.sample(n)[0].detach().requires_grad_()\n",
    "        psi2 = model.forward_DNN(x2)\n",
    "        \n",
    "        \n",
    "        psi_total = psi1*psi2\n",
    "        dfdx, = torch.autograd.grad(psi_total, x1, create_graph=True)\n",
    "        d2fdx2, = torch.autograd.grad(dfdx, x1, create_graph=True)\n",
    "        \n",
    "        kinetic1 = -0.5*d2fdx2/psi_total\n",
    "        potential1 = 0.5*x1**2\n",
    "\n",
    "        \n",
    "        dfdx, = torch.autograd.grad(psi_total, x2, create_graph=True)\n",
    "        d2fdx2, = torch.autograd.grad(dfdx, x2, create_graph=True)\n",
    "        \n",
    "        kinetic2 = -0.5*d2fdx2/psi_total\n",
    "        potential2 = 0.5*x2**2\n",
    "        \n",
    "\n",
    "        \n",
    "        E_L = (kinetic1 + potential1 + kinetic2 + potential2 + 1/torch.abs(x1-x2)).detach()\n",
    "        PE_acc += psi_total/psi_total.detach()*E_L\n",
    "        P_acc  += psi_total/psi_total.detach()\n",
    "        E_acc  += E_L   \n",
    "    \n",
    "    PE_acc /= N\n",
    "    P_acc  /= N\n",
    "    E_acc  /= N\n",
    "    \n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    \n",
    "    L2 = 0\n",
    "    for param in model.parameters():\n",
    "        L2 += torch.sum(param**2)\n",
    "\n",
    "    L2 /= params\n",
    "\n",
    "    loss = 2*(PE_acc - P_acc*E_acc)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "    \n",
    "    grad = 0\n",
    "    for param in model.parameters():\n",
    "        grad += torch.mean(param.grad**2)\n",
    "    \n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        print(model.Whh.weight)\n",
    "        print(f\"epoch: {epoch}, Grad: {grad}, Energy: {E_acc.item()}, N:{N}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e121e011111448f94d02edf53f1c3c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='x', max=4.0, min=-4.0, step=0.025), Output()), _dom_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c8f238bf6234e1da170fb947379db64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='x', max=4.0, min=-4.0), Output()), _dom_classes=('wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def f(x):\n",
    "    x_lin = torch.linspace(-4, 4, 100).reshape(100,-1)\n",
    "\n",
    "    model.resetHidden()\n",
    "    psi1 = model.forward_DNN(x_lin)[:,0].detach().numpy()\n",
    "\n",
    "    x = torch.Tensor([[x]])\n",
    "    #y = torch.Tensor([[y]])\n",
    "    \n",
    "    model.forward_RNN(x)\n",
    "    psi2 = model.forward_DNN(x_lin)[:,0].detach().numpy()\n",
    "\n",
    "    #model.forward_RNN(y)\n",
    "    #psi3 = model.forward_DNN(x_lin)[:,0].detach().numpy()\n",
    "\n",
    "    plt.plot(x_lin[:,0], psi1**2/np.sum(psi1**2), \"b\")\n",
    "    plt.plot(x_lin[:,0], psi2**2/np.sum(psi2**2), \"r\")\n",
    "    #plt.plot(x_lin[:,0], psi3**2/np.sum(psi3**2))\n",
    "    plt.plot(x, 0.01, \"bo\")\n",
    "    #plt.plot(y, 0.01, \"ro\")\n",
    "    plt.xlim((-4,4))\n",
    "    plt.ylim((0, 0.1))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def g(x):\n",
    "    model.resetHidden()\n",
    "\n",
    "    x = torch.Tensor([[x]])\n",
    "    #y = torch.Tensor([[y]])\n",
    "\n",
    "    plt.plot(model.hidden.detach().numpy(), \"bo\")\n",
    "    model.forward_RNN(x)\n",
    "    #model.forward_RNN(y)\n",
    "\n",
    "    plt.plot(model.hidden.detach().numpy(), \"ro\")\n",
    "    plt.xlim((-7,7))\n",
    "    plt.ylim((-1, 1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "interact(f, x=(-4.0, 4., 0.025));\n",
    "interact(g, x=(-4.0, 4., 0.1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.resetHidden()\n",
    "print(model.sample(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lin = torch.linspace(-4, 4, 100).reshape(100,-1)\n",
    "psi = model.forward(x_lin)[:,0].detach().numpy()\n",
    "\n",
    "plt.plot(x_lin[:,0], psi**2)\n",
    "plt.plot(x_lin[:,0], 1/np.sqrt(np.pi)*np.exp(-x_lin[:,0]**2), \"--\")\n",
    "plt.legend([\"DNN\", \"analytical\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:23<00:00, 120.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.595165491104126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N = 10000\n",
    "\n",
    "E = 0\n",
    "for i in tqdm(range(N)):\n",
    "    model.resetHidden() \n",
    "    x1 = model.sample(20)[0].detach().requires_grad_()\n",
    "    psi1 = model.forward_DNN(x1)\n",
    "\n",
    "    model.forward_RNN(x1)\n",
    "    x2 = model.sample(20)[0].detach().requires_grad_()\n",
    "    psi2 = model.forward_DNN(x2)\n",
    "\n",
    "\n",
    "    psi_total = psi1*psi2\n",
    "    dfdx, = torch.autograd.grad(psi_total, x1, create_graph=True)\n",
    "    d2fdx2, = torch.autograd.grad(dfdx, x1, create_graph=True)\n",
    "\n",
    "    kinetic1 = -0.5*d2fdx2/psi_total\n",
    "    potential1 = 0.5*x1**2\n",
    "\n",
    "\n",
    "    dfdx, = torch.autograd.grad(psi_total, x2, create_graph=True)\n",
    "    d2fdx2, = torch.autograd.grad(dfdx, x2, create_graph=True)\n",
    "\n",
    "    kinetic2 = -0.5*d2fdx2/psi_total\n",
    "    potential2 = 0.5*x2**2\n",
    "\n",
    "\n",
    "\n",
    "    E += (kinetic1 + potential1 + kinetic2 + potential2 + 1/torch.abs(x1-x2)).detach()\n",
    "\n",
    "E = E/N\n",
    "\n",
    "print(E.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.resetHidden() \n",
    "x1 = torch.Tensor([[0]]).requires_grad_()\n",
    "psi1 = model.forward_DNN(x1)\n",
    "\n",
    "model.forward_RNN(x1)\n",
    "x2 = torch.Tensor([[0]]).requires_grad_()\n",
    "psi2 = model.forward_DNN(x2)\n",
    "\n",
    "psi_total = psi1*psi2\n",
    "dfdx, = torch.autograd.grad(psi_total, x1, create_graph=True)\n",
    "d2fdx2, = torch.autograd.grad(dfdx, x1, create_graph=True)\n",
    "\n",
    "print(d2fdx2/psi_total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing auto grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [torch.Tensor([3]).requires_grad_(), torch.Tensor([6]).requires_grad_()]\n",
    "y = torch.Tensor([4, 8]).requires_grad_()\n",
    "\n",
    "f = torch.Tensor(x)**3*y**2\n",
    "\n",
    "print(f)\n",
    "#f.backward()\n",
    "#print(x.grad, y.grad)\n",
    "\n",
    "dfdx = [torch.autograd.grad(a, b, create_graph=True)[0] for a, b in zip(f, x)]\n",
    "print(dfdx)\n",
    "\n",
    "d2fdx2 = [torch.autograd.grad(a, b, create_graph=True)[0] for a, b in enumerate(dfdx, x)]\n",
    "\n",
    "print(d2fdx2)\n",
    "\n",
    "#d2fdx2.backward()\n",
    "#print(x.grad, y.grad)\n",
    "\n",
    "#print(dfdx)\n",
    "\n",
    "\n",
    "#ddfdxdx, = torch.autograd.grad(dfdx, x, create_graph=True)\n",
    "#print(ddfdxdx.grad_fn(x)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_neural",
   "language": "python",
   "name": "env_neural"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
