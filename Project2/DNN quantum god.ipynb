{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "hn = 3\n",
    "class Model(nn.Module):\n",
    "     \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.stepLength = 1.2\n",
    "        self.hidden = torch.zeros((1, hn))\n",
    "        \n",
    "        self.Whh = nn.Linear(hn, hn)\n",
    "        self.Whx = nn.Linear(1, hn, bias = False)\n",
    "        \n",
    "        self.layer1 = nn.Linear(1 + hn, 64)\n",
    "        self.layer2 = nn.Linear(64, 32)\n",
    "        self.layer3 = nn.Linear(32, 8)\n",
    "        self.layer4 = nn.Linear(8, 1)\n",
    "      \n",
    "    \n",
    "    def forward_RNN(self, x):\n",
    "        self.hidden = torch.tanh(self.Whh(self.hidden) + self.Whx(x))\n",
    "        \n",
    "        \n",
    "    def forward_DNN(self, x):\n",
    "        \n",
    "        y = torch.cat((self.hidden.repeat(x.shape[0], 1), x), 1)\n",
    "        \n",
    "        y = self.layer1(y).clamp(min=0)\n",
    "        y = self.layer2(y).clamp(min=0)\n",
    "        y = self.layer3(y).clamp(min=0)\n",
    "        y = self.layer4(y)\n",
    "     \n",
    "        return y*torch.exp(-0.1*x**2)\n",
    "    \n",
    "    def sample(self):\n",
    "        total = 0\n",
    "        x = torch.Tensor(4*np.random.random((1,1)) - 2)\n",
    "        psi_old = self.forward_DNN(x)\n",
    "        \n",
    "        for i in range(10):\n",
    "            x_new = x + 1.5*torch.Tensor(2*np.random.random((1,1)) - 1)\n",
    "            psi_new = self.forward_DNN(x_new)\n",
    "            \n",
    "            if (psi_new/psi_old)**2 > np.random.random():\n",
    "                x = x_new\n",
    "                psi_old = psi_new\n",
    "                total += 1\n",
    "            \n",
    "        return x, total\n",
    "    \n",
    "    def resetHidden(self):\n",
    "        self.hidden = torch.zeros((1, hn))\n",
    "        self.forward_RNN(torch.zeros((1, 1)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "model = Model()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using naive minimization of energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:00<07:24,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, Grad: 302.8515625, Energy: 2.267035484313965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 101/2000 [00:21<06:33,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100, Grad: 1.2957344055175781, Energy: 0.8138153553009033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 161/2000 [00:33<06:42,  4.57it/s]"
     ]
    }
   ],
   "source": [
    "epochs = 2000\n",
    "N = 30\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    PE_acc = 0\n",
    "    P_acc = 0\n",
    "    E_acc = 0\n",
    "    grad = 0\n",
    "    \n",
    "    for i in range(N):\n",
    "        psi_total = 1\n",
    "        \n",
    "        model.resetHidden() \n",
    "        x1 = model.sample()[0].detach().requires_grad_()\n",
    "        psi1 = model.forward_DNN(x1)\n",
    "        \n",
    "        model.forward_RNN(x1)\n",
    "        x2 = model.sample()[0].detach().requires_grad_()\n",
    "        psi2 = model.forward_DNN(x2)\n",
    "        \n",
    "        \n",
    "        psi_total = psi1*psi2\n",
    "        dfdx, = torch.autograd.grad(psi_total, x1, create_graph=True)\n",
    "        d2fdx2, = torch.autograd.grad(dfdx, x1, create_graph=True)\n",
    "        \n",
    "        kinetic1 = -0.5*d2fdx2/psi_total\n",
    "        potential1 = 0.5*x1**2\n",
    "\n",
    "        \n",
    "        dfdx, = torch.autograd.grad(psi_total, x2, create_graph=True)\n",
    "        d2fdx2, = torch.autograd.grad(dfdx, x2, create_graph=True)\n",
    "        \n",
    "        kinetic2 = -0.5*d2fdx2/psi_total\n",
    "        potential2 = 0.5*x2**2\n",
    "        \n",
    "\n",
    "        \n",
    "        E_L = (kinetic1 + potential1 + kinetic2 + potential2 + 0.1/torch.abs(x1-x2)).detach()\n",
    "        PE_acc += psi_total/psi_total.detach()*E_L\n",
    "        P_acc  += psi_total/psi_total.detach()\n",
    "        E_acc  += E_L   \n",
    "    \n",
    "    PE_acc /= N\n",
    "    P_acc  /= N\n",
    "    E_acc  /= N\n",
    "    \n",
    "    L2 = 0\n",
    "    for param in model.parameters():\n",
    "        L2 += torch.mean(param**2)\n",
    "        \n",
    "    \n",
    "    loss = 2*(PE_acc - P_acc*E_acc)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    grad = 0\n",
    "    for param in model.parameters():\n",
    "        grad += torch.mean(param.grad**2)\n",
    "    \n",
    "    \n",
    "    if epoch%100 == 0: \n",
    "        print(f\"epoch: {epoch}, Grad: {grad}, Energy: {E_acc.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bc5c78eba4b4384a505f79e91c3819d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='x', max=4.0, min=-4.0), Output()), _dom_classes=('wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c6b8a9b19f54c00858d2ae57efc5455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='x', max=4.0, min=-4.0), Output()), _dom_classes=('wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def f(x):\n",
    "    x_lin = torch.linspace(-5, 5, 100).reshape(100,-1)\n",
    "\n",
    "    model.resetHidden()\n",
    "    psi1 = model.forward_DNN(x_lin)[:,0].detach().numpy()\n",
    "\n",
    "    x = torch.Tensor([[x]])\n",
    "    #y = torch.Tensor([[y]])\n",
    "    \n",
    "    model.forward_RNN(x)\n",
    "    psi2 = model.forward_DNN(x_lin)[:,0].detach().numpy()\n",
    "\n",
    "    #model.forward_RNN(y)\n",
    "    #psi3 = model.forward_DNN(x_lin)[:,0].detach().numpy()\n",
    "\n",
    "    plt.plot(x_lin[:,0], psi1**2/np.sum(psi1**2), \"b\")\n",
    "    plt.plot(x_lin[:,0], psi2**2/np.sum(psi2**2), \"r\")\n",
    "    #plt.plot(x_lin[:,0], psi3**2/np.sum(psi3**2))\n",
    "    plt.plot(x, 0.01, \"bo\")\n",
    "    #plt.plot(y, 0.01, \"ro\")\n",
    "    plt.xlim((-5,5))\n",
    "    plt.ylim((0, 0.1))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def g(x):\n",
    "    model.resetHidden()\n",
    "\n",
    "    x = torch.Tensor([[x]])\n",
    "    #y = torch.Tensor([[y]])\n",
    "\n",
    "    plt.plot(model.hidden.detach().numpy(), \"bo\")\n",
    "    model.forward_RNN(x)\n",
    "    #model.forward_RNN(y)\n",
    "\n",
    "    plt.plot(model.hidden.detach().numpy(), \"ro\")\n",
    "    plt.xlim((-5,5))\n",
    "    plt.ylim((-1, 1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "interact(f, x=(-4.0, 4., 0.1));\n",
    "interact(g, x=(-4.0, 4., 0.1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[1.2257]]), 7)\n"
     ]
    }
   ],
   "source": [
    "model.resetHidden()\n",
    "print(model.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lin = torch.linspace(-4, 4, 100).reshape(100,-1)\n",
    "psi = model.forward(x_lin)[:,0].detach().numpy()\n",
    "\n",
    "plt.plot(x_lin[:,0], psi**2)\n",
    "plt.plot(x_lin[:,0], 1/np.sqrt(np.pi)*np.exp(-x_lin[:,0]**2), \"--\")\n",
    "plt.legend([\"DNN\", \"analytical\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:04<00:00, 154.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1279858350753784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N = 10000\n",
    "\n",
    "E = 0\n",
    "for i in tqdm(range(N)):\n",
    "    model.resetHidden() \n",
    "    x1 = model.sample()[0].detach().requires_grad_()\n",
    "    psi1 = model.forward_DNN(x1)\n",
    "\n",
    "    model.forward_RNN(x1)\n",
    "    x2 = model.sample()[0].detach().requires_grad_()\n",
    "    psi2 = model.forward_DNN(x2)\n",
    "\n",
    "    psi_total = psi1*psi2\n",
    "    dfdx, = torch.autograd.grad(psi_total, x1, create_graph=True)\n",
    "    d2fdx2, = torch.autograd.grad(dfdx, x1, create_graph=True)\n",
    "\n",
    "    kinetic1 = -0.5*d2fdx2/psi_total\n",
    "    potential1 = 0.5*x1**2\n",
    "\n",
    "    dfdx, = torch.autograd.grad(psi_total, x2, create_graph=True)\n",
    "    d2fdx2, = torch.autograd.grad(dfdx, x2, create_graph=True)\n",
    "\n",
    "    kinetic2 = -0.5*d2fdx2/psi_total\n",
    "    potential2 = 0.5*x2**2\n",
    "\n",
    "    E += (kinetic1 + potential1 + kinetic2 + potential2 + 0/torch.abs(x1-x2)).detach()\n",
    "\n",
    "E = E/N\n",
    "\n",
    "print(E.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing auto grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [torch.Tensor([3]).requires_grad_(), torch.Tensor([6]).requires_grad_()]\n",
    "y = torch.Tensor([4, 8]).requires_grad_()\n",
    "\n",
    "f = torch.Tensor(x)**3*y**2\n",
    "\n",
    "print(f)\n",
    "#f.backward()\n",
    "#print(x.grad, y.grad)\n",
    "\n",
    "dfdx = [torch.autograd.grad(a, b, create_graph=True)[0] for a, b in zip(f, x)]\n",
    "print(dfdx)\n",
    "\n",
    "d2fdx2 = [torch.autograd.grad(a, b, create_graph=True)[0] for a, b in enumerate(dfdx, x)]\n",
    "\n",
    "print(d2fdx2)\n",
    "\n",
    "#d2fdx2.backward()\n",
    "#print(x.grad, y.grad)\n",
    "\n",
    "#print(dfdx)\n",
    "\n",
    "\n",
    "#ddfdxdx, = torch.autograd.grad(dfdx, x, create_graph=True)\n",
    "#print(ddfdxdx.grad_fn(x)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_neural",
   "language": "python",
   "name": "env_neural"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
