{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hn = 16\n",
    "class Model(nn.Module):\n",
    "     \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.stepLength = 1.5\n",
    "        self.hidden = torch.zeros((1, hn))\n",
    "        \n",
    "        self.Whh = nn.Linear(hn, hn)\n",
    "        self.Whx = nn.Linear(1, hn, bias = False)\n",
    "        \n",
    "        self.layer1 = nn.Linear(1, 32)\n",
    "        self.layer2 = nn.Linear(32, 32)\n",
    "        self.layer3 = nn.Linear(32, hn)\n",
    "      \n",
    "    \n",
    "    def forward_RNN(self, x):\n",
    "        self.hidden = torch.tanh(self.Whh(self.hidden) + self.Whx(x))\n",
    "        \n",
    "        \n",
    "    def forward_DNN(self, x):\n",
    "        \n",
    "        y = torch.relu(self.layer1(x))\n",
    "        y = torch.relu(self.layer2(y))\n",
    "        y = self.layer3(y)\n",
    "     \n",
    "        return torch.sum(self.hidden.repeat(y.shape[0], 1)*y, dim = 1).reshape(-1, 1)*torch.exp(-0.01*x**2)\n",
    "    \n",
    "    def sample(self, n):\n",
    "        total = 0\n",
    "        x = torch.Tensor(4*np.random.random((1,1)) - 2)\n",
    "        psi_old = self.forward_DNN(x)\n",
    "        \n",
    "        for i in range(n):\n",
    "            x_new = x + self.stepLength*torch.Tensor(2*np.random.random((1,1)) - 1)\n",
    "            psi_new = self.forward_DNN(x_new)\n",
    "            \n",
    "            if (psi_new/psi_old)**2 > np.random.random():\n",
    "                x = x_new\n",
    "                psi_old = psi_new\n",
    "                total += 1\n",
    "            \n",
    "        return x, total\n",
    "    \n",
    "    def resetHidden(self):\n",
    "        self.hidden = torch.zeros((1, hn))\n",
    "        self.forward_RNN(torch.zeros((1, 1)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "model = Model()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using naive minimization of energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1000 [00:00<03:10,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, Grad: 417.98956298828125, Energy: 50.2562370300293, N:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 52/1000 [00:09<02:51,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 50, Grad: 44.584041595458984, Energy: 32.82907485961914, N:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 102/1000 [00:17<02:31,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100, Grad: 32.78792953491211, Energy: 14.179769515991211, N:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 152/1000 [00:26<02:29,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 150, Grad: 0.548678994178772, Energy: 5.482117652893066, N:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 202/1000 [00:35<02:21,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 200, Grad: 663.2507934570312, Energy: 8.137578964233398, N:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 252/1000 [00:44<02:14,  5.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 250, Grad: 176.05047607421875, Energy: 8.545910835266113, N:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 302/1000 [00:53<02:00,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 300, Grad: 278.53497314453125, Energy: 18.742992401123047, N:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 337/1000 [00:59<01:57,  5.66it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0c7af3a5eb21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_RNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mpsi2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_DNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-2d7daa211220>\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mpsi_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_DNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpsi_new\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mpsi_old\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mpsi_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpsi_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/newhd/Documents/neural/env_neural/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "N = 10\n",
    "n = 50\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    PE_acc = 0\n",
    "    P_acc = 0\n",
    "    E_acc = 0\n",
    "    grad = 0\n",
    "    \n",
    "    for i in range(N):\n",
    "        psi_total = 1\n",
    "        \n",
    "        model.resetHidden() \n",
    "        x1 = model.sample(n)[0].detach().requires_grad_()\n",
    "        psi1 = model.forward_DNN(x1)\n",
    "        \n",
    "        model.forward_RNN(x1)\n",
    "        x2 = model.sample(n)[0].detach().requires_grad_()\n",
    "        psi2 = model.forward_DNN(x2)\n",
    "        \n",
    "        \n",
    "        psi_total = psi1*psi2\n",
    "        dfdx, = torch.autograd.grad(psi_total, x1, create_graph=True)\n",
    "        d2fdx2, = torch.autograd.grad(dfdx, x1, create_graph=True)\n",
    "        \n",
    "        kinetic1 = -0.5*d2fdx2/psi_total\n",
    "        potential1 = 0.5*x1**2\n",
    "\n",
    "        \n",
    "        dfdx, = torch.autograd.grad(psi_total, x2, create_graph=True)\n",
    "        d2fdx2, = torch.autograd.grad(dfdx, x2, create_graph=True)\n",
    "        \n",
    "        kinetic2 = -0.5*d2fdx2/psi_total\n",
    "        potential2 = 0.5*x2**2\n",
    "        \n",
    "\n",
    "        \n",
    "        E_L = (kinetic1 + potential1 + kinetic2 + potential2 + 1/torch.abs(x1-x2)).detach()\n",
    "        PE_acc += psi_total/psi_total.detach()*E_L\n",
    "        P_acc  += psi_total/psi_total.detach()\n",
    "        E_acc  += E_L   \n",
    "    \n",
    "    PE_acc /= N\n",
    "    P_acc  /= N\n",
    "    E_acc  /= N\n",
    "    \n",
    "    loss = 2*(PE_acc - P_acc*E_acc)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    grad = 0\n",
    "    for param in model.parameters():\n",
    "        grad += torch.mean(param.grad**2)\n",
    "    \n",
    "    \n",
    "    if epoch%50 == 0: \n",
    "        print(f\"epoch: {epoch}, Grad: {grad}, Energy: {E_acc.item()}, N:{N}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "337a824c53fa4bd4b6360945096dbdbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='x', max=4.0, min=-4.0, step=0.025), Output()), _dom_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10ae81e4f4bc42bfa096326ed21765f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='x', max=4.0, min=-4.0), Output()), _dom_classes=('wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def f(x):\n",
    "    x_lin = torch.linspace(-4, 4, 100).reshape(100,-1)\n",
    "\n",
    "    model.resetHidden()\n",
    "    psi1 = model.forward_DNN(x_lin).detach().numpy()\n",
    "\n",
    "    x = torch.Tensor([[x]])\n",
    "    #y = torch.Tensor([[y]])\n",
    "    \n",
    "    model.forward_RNN(x)\n",
    "    psi2 = model.forward_DNN(x_lin).detach().numpy()\n",
    "\n",
    "    #model.forward_RNN(y)\n",
    "    #psi3 = model.forward_DNN(x_lin)[:,0].detach().numpy()\n",
    "\n",
    "    plt.plot(x_lin[:,0], psi1/np.sum(psi1**2), \"b\")\n",
    "    plt.plot(x_lin[:,0], psi2/np.sum(psi2**2), \"r\")\n",
    "    #plt.plot(x_lin[:,0], psi3**2/np.sum(psi3**2))\n",
    "    plt.plot(x, 0.01, \"bo\")\n",
    "    #plt.plot(y, 0.01, \"ro\")\n",
    "    #plt.xlim((-7,7))\n",
    "    plt.ylim((0, 0.1))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def g(x):\n",
    "    model.resetHidden()\n",
    "\n",
    "    x = torch.Tensor([[x]])\n",
    "    #y = torch.Tensor([[y]])\n",
    "\n",
    "    plt.plot(model.hidden.detach().numpy(), \"bo\")\n",
    "    model.forward_RNN(x)\n",
    "    #model.forward_RNN(y)\n",
    "\n",
    "    plt.plot(model.hidden.detach().numpy(), \"ro\")\n",
    "    plt.xlim((-7,7))\n",
    "    plt.ylim((-1, 1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "interact(f, x=(-4.0, 4., 0.025));\n",
    "interact(g, x=(-4.0, 4., 0.1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[1.7913]]), 20)\n"
     ]
    }
   ],
   "source": [
    "model.resetHidden()\n",
    "print(model.sample(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1f0eb1064380>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx_lin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpsi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_lin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_lin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsi\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_lin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx_lin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"--\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/newhd/Documents/neural/env_neural/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mregistered\u001b[0m \u001b[0mhooks\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatter\u001b[0m \u001b[0msilently\u001b[0m \u001b[0mignores\u001b[0m \u001b[0mthem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \"\"\"\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_lin = torch.linspace(-4, 4, 100).reshape(100,-1)\n",
    "psi = model.forward(x_lin)[:,0].detach().numpy()\n",
    "\n",
    "plt.plot(x_lin[:,0], psi**2)\n",
    "plt.plot(x_lin[:,0], 1/np.sqrt(np.pi)*np.exp(-x_lin[:,0]**2), \"--\")\n",
    "plt.legend([\"DNN\", \"analytical\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "\n",
    "E = 0\n",
    "n = 100\n",
    "for i in tqdm(range(N)):\n",
    "    model.resetHidden() \n",
    "    x1 = model.sample(n)[0].detach().requires_grad_()\n",
    "    psi1 = model.forward_DNN(x1)\n",
    "\n",
    "    model.forward_RNN(x1)\n",
    "    x2 = model.sample(n)[0].detach().requires_grad_()\n",
    "    psi2 = model.forward_DNN(x2)\n",
    "\n",
    "\n",
    "    psi_total = psi1*psi2\n",
    "    dfdx, = torch.autograd.grad(psi_total, x1, create_graph=True)\n",
    "    d2fdx2, = torch.autograd.grad(dfdx, x1, create_graph=True)\n",
    "\n",
    "    kinetic1 = -0.5*d2fdx2/psi_total\n",
    "    potential1 = 0.5*x1**2\n",
    "\n",
    "\n",
    "    dfdx, = torch.autograd.grad(psi_total, x2, create_graph=True)\n",
    "    d2fdx2, = torch.autograd.grad(dfdx, x2, create_graph=True)\n",
    "\n",
    "    kinetic2 = -0.5*d2fdx2/psi_total\n",
    "    potential2 = 0.5*x2**2\n",
    "\n",
    "\n",
    "\n",
    "    E += (kinetic1 + potential1 + kinetic2 + potential2 + 0/torch.abs(x1-x2)).detach()\n",
    "    \n",
    "    if i%1000 == 0:\n",
    "        print(E.item()/(i+1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.resetHidden() \n",
    "x1 = torch.Tensor([[0]]).requires_grad_()\n",
    "psi1 = model.forward_DNN(x1)\n",
    "\n",
    "model.forward_RNN(x1)\n",
    "x2 = torch.Tensor([[0]]).requires_grad_()\n",
    "psi2 = model.forward_DNN(x2)\n",
    "\n",
    "psi_total = psi1*psi2\n",
    "dfdx, = torch.autograd.grad(psi_total, x1, create_graph=True)\n",
    "d2fdx2, = torch.autograd.grad(dfdx, x1, create_graph=True)\n",
    "\n",
    "print(d2fdx2/psi_total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing auto grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [torch.Tensor([3]).requires_grad_(), torch.Tensor([6]).requires_grad_()]\n",
    "y = torch.Tensor([4, 8]).requires_grad_()\n",
    "\n",
    "f = torch.Tensor(x)**3*y**2\n",
    "\n",
    "print(f)\n",
    "#f.backward()\n",
    "#print(x.grad, y.grad)\n",
    "\n",
    "dfdx = [torch.autograd.grad(a, b, create_graph=True)[0] for a, b in zip(f, x)]\n",
    "print(dfdx)\n",
    "\n",
    "d2fdx2 = [torch.autograd.grad(a, b, create_graph=True)[0] for a, b in enumerate(dfdx, x)]\n",
    "\n",
    "print(d2fdx2)\n",
    "\n",
    "#d2fdx2.backward()\n",
    "#print(x.grad, y.grad)\n",
    "\n",
    "#print(dfdx)\n",
    "\n",
    "\n",
    "#ddfdxdx, = torch.autograd.grad(dfdx, x, create_graph=True)\n",
    "#print(ddfdxdx.grad_fn(x)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_neural",
   "language": "python",
   "name": "env_neural"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
